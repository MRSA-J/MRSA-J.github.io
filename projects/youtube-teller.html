<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/8726c43671fb992b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-29ebadaebe2fcb3f.js"/><script src="/_next/static/chunks/4bd1b696-ad45a0d75f1c7ab5.js" async=""></script><script src="/_next/static/chunks/684-b8fad8f1047091e2.js" async=""></script><script src="/_next/static/chunks/main-app-8afa1fecc1cfe7ee.js" async=""></script><script src="/_next/static/chunks/ee560e2c-d1d7047268cdf425.js" async=""></script><script src="/_next/static/chunks/995-7eef7c94b48cf075.js" async=""></script><script src="/_next/static/chunks/app/projects/layout-0fdc04bdfa674332.js" async=""></script><script src="/_next/static/chunks/63-135a55e29e0af163.js" async=""></script><script src="/_next/static/chunks/app/projects/%5Bslug%5D/page-6135a9dd7ef5736d.js" async=""></script><meta name="next-size-adjust" content=""/><title>YouTube Teller | Chen Wei</title><meta name="description" content="A video storytelling model that automatically generates descriptive captions for YouTube videos using deep learning techniques."/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="225x225"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_5cfdac __variable_9a8899 antialiased bg-white dark:bg-zinc-900 text-zinc-900 dark:text-zinc-100"><header class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><a class="font-bold text-xl" href="/"><span class="gradient-text">0xChen</span></a></div><nav class="hidden md:flex space-x-8"><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#about">About</a><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#experience">Experience</a><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#skills">Skills</a><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#projects">Projects</a><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#hobby">Hobby</a><a class="text-zinc-600 hover:text-zinc-900 dark:text-zinc-300 dark:hover:text-white transition-colors" href="#contact">Contact</a></nav><div class="md:hidden"><button type="button" class="text-zinc-600 dark:text-zinc-300 hover:text-zinc-900 dark:hover:text-white"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main class="pt-20 min-h-screen"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><a class="inline-flex items-center text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white mb-8" href="/#projects"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="mr-2" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg><span>Back to all projects</span></a><article class="bg-white dark:bg-zinc-800/50 rounded-xl shadow-sm overflow-hidden"><div class="relative h-64 sm:h-80 md:h-96 w-full bg-blue-500"><img alt="YouTube Teller System Architecture" loading="lazy" decoding="async" data-nimg="fill" class="transition-all duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;object-position:center;color:transparent" src="/projects/mldl/Youtube-Teller.jpeg"/></div><div class="p-6 sm:p-8"><h1 class="text-3xl sm:text-4xl font-bold mb-2">YouTube Teller</h1><div class="flex flex-wrap items-center gap-4 mb-6 text-zinc-500 dark:text-zinc-400"><div class="flex items-center"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="mr-1" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg><span>December 2022</span></div><div class="flex items-center"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="mr-1" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line></svg><span>Machine Learning/Deep Learning</span></div></div><p class="text-lg text-zinc-700 dark:text-zinc-300 mb-8">A video storytelling model that automatically generates descriptive captions for YouTube videos using deep learning techniques.</p><div class="space-y-4 mb-8"><p class="text-zinc-600 dark:text-zinc-400">YouTube Teller is a video captioning system that analyzes video frames to generate coherent natural language descriptions of the content. This project was developed as part of a team effort to improve video accessibility and searchability.</p><p class="text-zinc-600 dark:text-zinc-400">The system uses a combination of computer vision and natural language processing techniques. We extract frames from videos at various intervals and process them through a CLIP encoder to understand the visual content.</p><p class="text-zinc-600 dark:text-zinc-400">For the language generation component, we implemented a transformer-based architecture with a GPT-2 pretrained model to produce fluent and contextually relevant captions based on the visual features.</p><p class="text-zinc-600 dark:text-zinc-400">We experimented with three different approaches for frame selection: single frame analysis, sequential frame processing, and mean frame representation. Our evaluation showed that the mean frame approach achieved the best results across multiple metrics.</p><p class="text-zinc-600 dark:text-zinc-400">The model was trained and evaluated on the YouTubeClips dataset, which contains short video clips with human-annotated descriptions. Our system achieved strong performance on standard metrics including BLEU (0.520), CIDEr (0.584), METEOR (0.302), and ROUGE (0.647).</p><p class="text-zinc-600 dark:text-zinc-400">My primary contributions to this project included preprocessing the dataset, implementing the caption generator using the GPT-2 pretrained model, and conducting ablation studies to analyze the impact of different components on the overall performance.</p></div><div class="flex flex-wrap gap-2 mb-8"><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">Python</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">PyTorch</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">Computer Vision</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">NLP</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">CLIP</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">Transformer</span><span class="px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200">GPT-2</span></div><div class="flex flex-wrap gap-4 pt-4 border-t border-zinc-100 dark:border-zinc-700"><a href="https://github.com/MRSA-J/Youtube-Teller" target="_blank" rel="noopener noreferrer" class="flex items-center px-4 py-2 bg-zinc-100 dark:bg-zinc-800 hover:bg-zinc-200 dark:hover:bg-zinc-700 rounded-lg text-zinc-800 dark:text-zinc-200 transition-colors"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="mr-2" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg><span>View on GitHub</span></a><a href="https://devpost.com/software/video-storytelling" target="_blank" rel="noopener noreferrer" class="flex items-center px-4 py-2 bg-indigo-500 hover:bg-indigo-600 rounded-lg text-white transition-colors"><svg class="mr-2" width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M6.002 1.61L0 12.004L6.002 22.39h11.996L24 12.004L17.998 1.61H6.002zm1.593 16.526h-1.58V5.864h1.58v12.272zm4.006-5.523L9.43 11.108h2.79l2.172 1.505-2.172 1.504H9.43l2.172-1.504zm3.798 5.523h-1.581V5.864h1.581v12.272z"></path></svg><span>View on DevPost</span></a></div></div></article><!--$--><!--/$--><!--$--><!--/$--></div></main><footer class="bg-zinc-100 dark:bg-zinc-900 py-12 px-4 sm:px-6 lg:px-8"><div class="max-w-7xl mx-auto"><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8 mb-8"><div><h3 class="text-lg font-bold mb-4 accent-text">Chen Wei</h3><p class="text-zinc-600 dark:text-zinc-400 mb-4">A showcase of my work, skills, and professional journey as a Full-Stack Software Engineer and Computer Scientist.</p></div><div><h3 class="text-lg font-bold mb-4">Quick Links</h3><ul class="space-y-2"><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#about">About</a></li><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#experience">Experience</a></li><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#skills">Skills</a></li><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#projects">Projects</a></li><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#hobby">Hobby</a></li><li><a class="text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors" href="#contact">Contact</a></li></ul></div><div><h3 class="text-lg font-bold mb-4">Contact</h3><address class="not-italic text-zinc-600 dark:text-zinc-400"><p>Providence, RI, US</p><p class="mt-2"><a href="mailto:chen_wei@alumni.brown.edu" class="hover:text-zinc-900 dark:hover:text-white transition-colors">chen_wei@alumni.brown.edu</a></p><p class="mt-2"><a href="https://www.linkedin.com/in/chen-wei-57b225198/" class="hover:text-zinc-900 dark:hover:text-white transition-colors">LinkedIn Profile</a></p><p class="mt-2"><a href="https://mrsa-j.github.io/" class="hover:text-zinc-900 dark:hover:text-white transition-colors" target="_blank" rel="noopener noreferrer">Blog</a></p><p class="mt-2"><a href="https://happydoggie666.github.io/portfolio/" class="hover:text-zinc-900 dark:hover:text-white transition-colors" target="_blank" rel="noopener noreferrer">Design Portfolio</a></p></address></div><div><h3 class="text-lg font-bold mb-4">Follow Me</h3><div class="flex space-x-4"><a href="https://github.com/chenwei-profile" target="_blank" rel="noopener noreferrer" aria-label="GitHub" class="w-10 h-10 bg-white dark:bg-zinc-800 flex items-center justify-center rounded-full text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors shadow-sm hover:shadow-md"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a><a href="https://www.linkedin.com/in/chen-wei-57b225198/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn" class="w-10 h-10 bg-white dark:bg-zinc-800 flex items-center justify-center rounded-full text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors shadow-sm hover:shadow-md"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="https://mrsa-j.github.io/" target="_blank" rel="noopener noreferrer" aria-label="Blog" class="w-10 h-10 bg-white dark:bg-zinc-800 flex items-center justify-center rounded-full text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors shadow-sm hover:shadow-md"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"></path><path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"></path></svg></a><a href="https://happydoggie666.github.io/portfolio/" target="_blank" rel="noopener noreferrer" aria-label="Design Portfolio" class="w-10 h-10 bg-white dark:bg-zinc-800 flex items-center justify-center rounded-full text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors shadow-sm hover:shadow-md"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect><line x1="3" y1="9" x2="21" y2="9"></line><line x1="9" y1="21" x2="9" y2="9"></line></svg></a><a href="mailto:chen_wei@alumni.brown.edu" target="_blank" rel="noopener noreferrer" aria-label="Email" class="w-10 h-10 bg-white dark:bg-zinc-800 flex items-center justify-center rounded-full text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white transition-colors shadow-sm hover:shadow-md"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg></a></div></div></div><div class="pt-8 border-t border-zinc-200 dark:border-zinc-800 text-center"><p class="text-zinc-600 dark:text-zinc-400">© <!-- -->2025<!-- --> Chen Wei. All rights reserved.</p><p class="mt-2 text-sm text-zinc-500 dark:text-zinc-500">Built with Next.js, TypeScript, and Tailwind CSS  ✨🪐</p></div></div></footer><script src="/_next/static/chunks/webpack-29ebadaebe2fcb3f.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[4615,[\"844\",\"static/chunks/ee560e2c-d1d7047268cdf425.js\",\"995\",\"static/chunks/995-7eef7c94b48cf075.js\",\"998\",\"static/chunks/app/projects/layout-0fdc04bdfa674332.js\"],\"default\"]\n5:I[6874,[\"844\",\"static/chunks/ee560e2c-d1d7047268cdf425.js\",\"995\",\"static/chunks/995-7eef7c94b48cf075.js\",\"998\",\"static/chunks/app/projects/layout-0fdc04bdfa674332.js\"],\"\"]\n6:I[6821,[\"844\",\"static/chunks/ee560e2c-d1d7047268cdf425.js\",\"995\",\"static/chunks/995-7eef7c94b48cf075.js\",\"998\",\"static/chunks/app/projects/layout-0fdc04bdfa674332.js\"],\"default\"]\n7:I[3063,[\"63\",\"static/chunks/63-135a55e29e0af163.js\",\"419\",\"static/chunks/app/projects/%5Bslug%5D/page-6135a9dd7ef5736d.js\"],\"Image\"]\n8:I[9665,[],\"MetadataBoundary\"]\na:I[9665,[],\"OutletBoundary\"]\nd:I[4911,[],\"AsyncMetadataOutlet\"]\nf:I[9665,[],\"ViewportBoundary\"]\n11:I[6614,[],\"\"]\n:HL[\"/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/8726c43671fb992b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"VGsTyQcR2usZlOtmutfaF\",\"p\":\"\",\"c\":[\"\",\"projects\",\"youtube-teller\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[[\"slug\",\"youtube-teller\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/8726c43671fb992b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_5cfdac __variable_9a8899 antialiased bg-white dark:bg-zinc-900 text-zinc-900 dark:text-zinc-100\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[[\"$\",\"$L4\",null,{}],[\"$\",\"main\",null,{\"className\":\"pt-20 min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/#projects\",\"className\":\"inline-flex items-center text-zinc-600 dark:text-zinc-400 hover:text-zinc-900 dark:hover:text-white mb-8\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"none\",\"strokeWidth\":\"2\",\"viewBox\":\"0 0 24 24\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"mr-2\",\"children\":[\"$undefined\",[[\"$\",\"line\",\"0\",{\"x1\":\"19\",\"y1\":\"12\",\"x2\":\"5\",\"y2\":\"12\",\"children\":[]}],[\"$\",\"polyline\",\"1\",{\"points\":\"12 19 5 12 12 5\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"Back to all projects\"}]]}],[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]}],[\"$\",\"$L6\",null,{}]]]}],{\"children\":[[\"slug\",\"youtube-teller\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"article\",null,{\"className\":\"bg-white dark:bg-zinc-800/50 rounded-xl shadow-sm overflow-hidden\",\"children\":[[\"$\",\"div\",null,{\"className\":\"relative h-64 sm:h-80 md:h-96 w-full bg-blue-500\",\"children\":[\"$\",\"$L7\",null,{\"src\":\"/projects/mldl/Youtube-Teller.jpeg\",\"alt\":\"YouTube Teller System Architecture\",\"fill\":true,\"style\":{\"objectFit\":\"cover\",\"objectPosition\":\"center\"},\"className\":\"transition-all duration-300\"}]}],[\"$\",\"div\",null,{\"className\":\"p-6 sm:p-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-3xl sm:text-4xl font-bold mb-2\",\"children\":\"YouTube Teller\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-4 mb-6 text-zinc-500 dark:text-zinc-400\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"none\",\"strokeWidth\":\"2\",\"viewBox\":\"0 0 24 24\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"mr-1\",\"children\":[\"$undefined\",[[\"$\",\"rect\",\"0\",{\"x\":\"3\",\"y\":\"4\",\"width\":\"18\",\"height\":\"18\",\"rx\":\"2\",\"ry\":\"2\",\"children\":[]}],[\"$\",\"line\",\"1\",{\"x1\":\"16\",\"y1\":\"2\",\"x2\":\"16\",\"y2\":\"6\",\"children\":[]}],[\"$\",\"line\",\"2\",{\"x1\":\"8\",\"y1\":\"2\",\"x2\":\"8\",\"y2\":\"6\",\"children\":[]}],[\"$\",\"line\",\"3\",{\"x1\":\"3\",\"y1\":\"10\",\"x2\":\"21\",\"y2\":\"10\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"December 2022\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"none\",\"strokeWidth\":\"2\",\"viewBox\":\"0 0 24 24\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"mr-1\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z\",\"children\":[]}],[\"$\",\"line\",\"1\",{\"x1\":\"7\",\"y1\":\"7\",\"x2\":\"7.01\",\"y2\":\"7\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"Machine Learning/Deep Learning\"}]]}]]}],[\"$\",\"p\",null,{\"className\":\"text-lg text-zinc-700 dark:text-zinc-300 mb-8\",\"children\":\"A video storytelling model that automatically generates descriptive captions for YouTube videos using deep learning techniques.\"}],[\"$\",\"div\",null,{\"className\":\"space-y-4 mb-8\",\"children\":[[\"$\",\"p\",\"0\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"YouTube Teller is a video captioning system that analyzes video frames to generate coherent natural language descriptions of the content. This project was developed as part of a team effort to improve video accessibility and searchability.\"}],[\"$\",\"p\",\"1\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"The system uses a combination of computer vision and natural language processing techniques. We extract frames from videos at various intervals and process them through a CLIP encoder to understand the visual content.\"}],[\"$\",\"p\",\"2\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"For the language generation component, we implemented a transformer-based architecture with a GPT-2 pretrained model to produce fluent and contextually relevant captions based on the visual features.\"}],[\"$\",\"p\",\"3\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"We experimented with three different approaches for frame selection: single frame analysis, sequential frame processing, and mean frame representation. Our evaluation showed that the mean frame approach achieved the best results across multiple metrics.\"}],[\"$\",\"p\",\"4\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"The model was trained and evaluated on the YouTubeClips dataset, which contains short video clips with human-annotated descriptions. Our system achieved strong performance on standard metrics including BLEU (0.520), CIDEr (0.584), METEOR (0.302), and ROUGE (0.647).\"}],[\"$\",\"p\",\"5\",{\"className\":\"text-zinc-600 dark:text-zinc-400\",\"children\":\"My primary contributions to this project included preprocessing the dataset, implementing the caption generator using the GPT-2 pretrained model, and conducting ablation studies to analyze the impact of different components on the overall performance.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-8\",\"children\":[[\"$\",\"span\",\"Python\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"Python\"}],[\"$\",\"span\",\"PyTorch\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"PyTorch\"}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"Computer Vision\"}],[\"$\",\"span\",\"NLP\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"NLP\"}],[\"$\",\"span\",\"CLIP\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"CLIP\"}],[\"$\",\"span\",\"Transformer\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"Transformer\"}],[\"$\",\"span\",\"GPT-2\",{\"className\":\"px-3 py-1 bg-zinc-100 dark:bg-zinc-700 rounded-full text-sm font-medium text-zinc-800 dark:text-zinc-200\",\"children\":\"GPT-2\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 pt-4 border-t border-zinc-100 dark:border-zinc-700\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://github.com/MRSA-J/Youtube-Teller\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"flex items-center px-4 py-2 bg-zinc-100 dark:bg-zinc-800 hover:bg-zinc-200 dark:hover:bg-zinc-700 rounded-lg text-zinc-800 dark:text-zinc-200 transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"none\",\"strokeWidth\":\"2\",\"viewBox\":\"0 0 24 24\",\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"mr-2\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"View on GitHub\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://devpost.com/software/video-storytelling\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"flex items-center px-4 py-2 bg-indigo-500 hover:bg-indigo-600 rounded-lg text-white transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"mr-2\",\"width\":\"20\",\"height\":\"20\",\"viewBox\":\"0 0 24 24\",\"fill\":\"currentColor\",\"children\":[\"$\",\"path\",null,{\"d\":\"M6.002 1.61L0 12.004L6.002 22.39h11.996L24 12.004L17.998 1.61H6.002zm1.593 16.526h-1.58V5.864h1.58v12.272zm4.006-5.523L9.43 11.108h2.79l2.172 1.505-2.172 1.504H9.43l2.172-1.504zm3.798 5.523h-1.581V5.864h1.581v12.272z\"}]}],[\"$\",\"span\",null,{\"children\":\"View on DevPost\"}]]}],false,false]}]]}]]}],[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"QLfZCoqJhWVhDbeRNl5uh\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[4911,[],\"AsyncMetadata\"]\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"YouTube Teller | Chen Wei\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A video storytelling model that automatically generates descriptive captions for YouTube videos using deep learning techniques.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"225x225\"}]],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>